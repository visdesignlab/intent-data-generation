{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"./Data/study/study.json.gz\", 'rt') as zipfile:\n",
    "    studyProvenanceDB = json.load(zipfile)\n",
    "    \n",
    "with gzip.open(\"./Data/task/task.json.gz\", 'rt') as zipfile:\n",
    "    taskProvenanceDB = json.load(zipfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/codeDict.pickle\", \"rb\") as f:\n",
    "  codeDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFromMainDB(path):\n",
    "  return studyProvenanceDB[path]\n",
    "  \n",
    "def getFromGraphDB(path):\n",
    "  res = None\n",
    "  for p in path.split(\"/\"):\n",
    "    if res is None:\n",
    "      res = taskProvenanceDB[p]\n",
    "    else:\n",
    "      res = res[p]\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalFeedbackQuestions = [\n",
    "    {\n",
    "\n",
    "    \"question\": \"How helpful is the “individual selection” of points feature?\",\n",
    "    \"lowText\": \"Not Helpful\",\n",
    "    \"highText\": \"Very Helpful\"\n",
    "  },\n",
    "  {\n",
    "\n",
    "    \"question\": \"How helpful is the rectangle selection feature?\",\n",
    "    \"lowText\": \"Not Helpful\",\n",
    "    \"highText\": \"Very Helpful\"\n",
    "  },\n",
    "  {\n",
    "\n",
    "    \"question\": \"How helpful is the paintbrush feature?\",\n",
    "    \"lowText\": \"Not Helpful\",\n",
    "    \"highText\": \"Very Helpful\"\n",
    "  },\n",
    "  {\n",
    "\n",
    "    \"question\": \"How easy was the prediction interface to use?\",\n",
    "    \"lowText\": \"Very Difficult\",\n",
    "    \"highText\": \"Very Easy\"\n",
    "  },\n",
    "  {\n",
    "\n",
    "    \"question\": \"How accurate did you find the predictions?\",\n",
    "    \"lowText\": \"Not Accurate\",\n",
    "    \"highText\": \"Very Accurate\"\n",
    "  },\n",
    "  {\n",
    "\n",
    "    \"question\": \"How helpful did you find the predictions?\",\n",
    "    \"lowText\": \"Not Helpful\",\n",
    "    \"highText\": \"Very Helpful\"\n",
    "  },\n",
    "  {\n",
    "\n",
    "    \"question\": \"Do you prefer user-driven or computer supported selections?\",\n",
    "    \"lowText\": \"Strongly prefer user-driven\",\n",
    "    \"highText\": \"Strongly prefer computer supported\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"How experienced are you with scatterplots?\",\n",
    "    \"lowText\": \"Not experienced\",\n",
    "    \"highText\": \"Very experienced\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"How experienced are you with statistics?\"\n",
    "   ,\n",
    "    \"lowText\": \"Not experienced\",\n",
    "    \"highText\": \"Very experienced\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierBaseTypeDict = {\n",
    "    \"out_easy_training_1\":\"cluster\",\n",
    "\"out_easy_task_1\":\"cluster\",\n",
    "\"out_easy_task_2\":\"cluster\",\n",
    "\"out_easy_task_3\":\"linear\",\n",
    "\"out_easy_task_4\":\"linear\",\n",
    "\"out_easy_task_5\":\"curve\",\n",
    "\"out_med_training_1\":\"cluster\",\n",
    "\"out_med_task_1\":\"cluster\",\n",
    "\"out_med_task_2\":\"cluster\",\n",
    "\"out_med_task_3\":\"linear\",\n",
    "\"out_med_task_4\":\"linear\",\n",
    "\"out_med_task_5\":\"curve\",\n",
    "\"out_hard_training_1\":\"cluster\",\n",
    "\"out_hard_task_1\":\"cluster\",\n",
    "\"out_hard_task_2\":\"cluster\",\n",
    "\"out_hard_task_3\":\"linear\",\n",
    "\"out_hard_task_4\":\"linear\",\n",
    "\"out_hard_task_5\":\"curve\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def parseCode(data, stop=True):\n",
    "    root = \"\"\n",
    "    nodes = data['nodes']\n",
    "    for i,v in nodes.items():\n",
    "        if 'parent' in v:\n",
    "            nodes[v['parent']]['children'] = []\n",
    "            nodes[v['parent']]['children'].append(v['id'])\n",
    "        if v['label'] == \"Root\":\n",
    "            root = v['id']\n",
    "    temp = root\n",
    "    taskDict = {}\n",
    "    tasks = []\n",
    "\n",
    "    while True:\n",
    "        state = nodes[temp]['state']\n",
    "        children = []\n",
    "        if 'children' in nodes[temp]:\n",
    "            children = nodes[temp]['children']\n",
    "        taskId = state['taskId']\n",
    "        if taskId not in taskDict:\n",
    "            taskDict[taskId] = []\n",
    "        taskDict[taskId].append(nodes[temp])\n",
    "#         if \"Final Feedback\" in nodes[temp]['label']:\n",
    "#             pprint.pprint(nodes[temp]['label'])\n",
    "#             pprint.pprint(nodes[temp]['state'])\n",
    "        if len(children) == 0: break\n",
    "        temp = children[0]\n",
    "\n",
    "\n",
    "    for taskId, taskProvenance in taskDict.items():\n",
    "        taskDets = {}\n",
    "        if taskId == \"-1\":\n",
    "            continue\n",
    "        taskProvenance = sorted(taskProvenance, key=lambda x: x['metadata']['createdOn'])\n",
    "        taskDets['id'] = taskId\n",
    "        startNode = next(filter(lambda x: \"Start task:\" in x['label'], taskProvenance), False)\n",
    "        endNode = next(filter(lambda x: \"Complete task:\" in x['label'], taskProvenance), False)\n",
    "        if(type(endNode) == bool):\n",
    "            continue\n",
    "\n",
    "        taskStartTime  = startNode['metadata']['createdOn']\n",
    "        taskEndTime = endNode['metadata']['createdOn']\n",
    "        timeRequired = datetime.fromtimestamp(taskEndTime / 1000) - datetime.fromtimestamp(taskStartTime / 1000)\n",
    "\n",
    "        state = endNode['state']\n",
    "\n",
    "        task = state['task']\n",
    "\n",
    "        autoCompleteUsed = False\n",
    "        rankOfPredictionUsed = -1\n",
    "        totalPredictionsMade = -1\n",
    "        selectionDetails = {\n",
    "            'rectangular': {\n",
    "                'timestamps': [],\n",
    "                'occurences': 0\n",
    "            },\n",
    "            'paint': {\n",
    "                'timestamps': [],\n",
    "                'occurences': 0\n",
    "            },\n",
    "            'cleared': {\n",
    "                'timestamps': [],\n",
    "                'occurences': 0\n",
    "            },\n",
    "            'invert': {\n",
    "                'timestamps': [],\n",
    "                'occurences': 0\n",
    "            }\n",
    "        }\n",
    "        selectedPrediction = \"\"\n",
    "\n",
    "        graphPath = state['graph']\n",
    "        graph = {}\n",
    "        if task['manual'] == \"supported\" and stop:\n",
    "          graph = getFromGraphDB(graphPath)\n",
    "          gNodes = graph['nodes']\n",
    "          for i,v in gNodes.items():\n",
    "            label = v['label']\n",
    "            time = v['metadata']['createdOn']\n",
    "            if 'Point Selection' in label:\n",
    "              selectionDetails['paint']['occurences'] += 1\n",
    "              selectionDetails['paint']['timestamps'].append(time)\n",
    "            if 'Add brush to plot' in label:\n",
    "              selectionDetails['rectangular']['occurences'] += 1\n",
    "              selectionDetails['rectangular']['timestamps'].append(time)\n",
    "            if 'Clear all' in label:\n",
    "              selectionDetails['cleared']['occurences'] += 1\n",
    "              selectionDetails['cleared']['timestamps'].append(time)\n",
    "            if 'Invert' in label:\n",
    "              selectionDetails['invert']['occurences'] += 1\n",
    "              selectionDetails['invert']['timestamps'].append(time)\n",
    "            if 'turnedPrediction' in v['state'].keys():\n",
    "              selectedPrediction = v['state']['turnedPrediction']\n",
    "              if 'extra' in gNodes[v['parent']]['artifacts']:\n",
    "                extra = gNodes[v['parent']]['artifacts']['extra']\n",
    "                extra = list(extra.values())\n",
    "                if len(extra) > 0 or '0' in extra:\n",
    "                  if 'predictions' in extra[0]['e']['predictionSet']:\n",
    "                    predictions = extra[0]['e']['predictionSet']['predictions']\n",
    "                    predictions = list(predictions.values())\n",
    "                    predictions = sorted(predictions, key=lambda x: x['rank'], reverse=True)\n",
    "                    selectedIdxes = [i for i,x in enumerate(predictions) if x['intent'] == selectedPrediction]\n",
    "                    if len(selectedIdxes) > 0:\n",
    "                      autoCompleteUsed = True\n",
    "                      rankOfPredictionUsed = selectedIdxes[0] + 1\n",
    "                      totalPredictionsMade = len(predictions)\n",
    "                      nameArr =  selectedPrediction.split(\":\")\n",
    "                      intentName = nameArr[2]\n",
    "                      if \"Regression\" in intentName:\n",
    "                        intentName = f\"{intentName} - {nameArr[3]}\"\n",
    "                      selectedPrediction = intentName\n",
    "                      \n",
    "    \n",
    "        interactionDetails = {}\n",
    "        interactionDetails['autoCompleteUsed'] = autoCompleteUsed\n",
    "        interactionDetails['rankOfPredictionUsed'] = rankOfPredictionUsed\n",
    "        interactionDetails['totalPredictionsMade'] = totalPredictionsMade\n",
    "        interactionDetails['selectionDetails'] = selectionDetails\n",
    "        interactionDetails['selectedPrediction'] = selectedPrediction\n",
    "\n",
    "        taskDets['type'] = task['type']\n",
    "        taskDets['training'] = task['training']\n",
    "        taskDets['task'] = task['task']\n",
    "        taskDets['dataset'] = task['dataset']\n",
    "        taskDets['difficulty'] = task['difficulty']\n",
    "        taskDets['user-driven'] = task['manual']\n",
    "        taskDets['user_confidence'] = state['confidenceScore']\n",
    "        taskDets['user_difficulty'] = state['difficultyScore']\n",
    "        taskDets['user_task_feedback'] = state['feedback']\n",
    "        taskDets['selections'] = state['selections']\n",
    "        taskDets['graph'] = endNode['state']['graph']\n",
    "        taskDets['interactionDetails'] = interactionDetails\n",
    "\n",
    "        taskDets['startedAt'] = str(datetime.fromtimestamp(taskStartTime/1000))\n",
    "        taskDets['completedAt'] = str(datetime.fromtimestamp(taskEndTime/1000))\n",
    "        taskDets['timeRequired'] = str(timeRequired)\n",
    "        tasks.append(taskDets)\n",
    "    # break\n",
    "\n",
    "    return pd.DataFrame(tasks)\n",
    "\n",
    "# res = getStudyResultsFor(prov_runs[6])\n",
    "# pprint.pprint(res['data']['tasks'][\"33\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStudyProvenanceFor(data):\n",
    "    nodes = data['nodes']\n",
    "\n",
    "    newNode = []\n",
    "\n",
    "    for n in nodes.values():\n",
    "        label = n['label']\n",
    "        time = n['metadata']['createdOn']\n",
    "        state = n['state']\n",
    "        state['label'] = label\n",
    "        state['time'] = time\n",
    "        newNode.append(state)\n",
    "\n",
    "    newNode = sorted(newNode, key=lambda x: x['time'])\n",
    "    return newNode[0]['participantId'], newNode\n",
    "\n",
    "def getStudyProvenanceForMultiple(dataArr):\n",
    "    events = []\n",
    "    for d in dataArr:\n",
    "        event = {}\n",
    "        id,evt = getStudyProvenanceFor(d)\n",
    "        event['id'] = id\n",
    "        event['data'] = evt\n",
    "        events.append(event)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jaccard\n",
    "from numpy import interp\n",
    "import copy\n",
    "\n",
    "def parseFeedback(scores):\n",
    "    feed = []\n",
    "    for idx,score in enumerate(scores):\n",
    "        question = finalFeedbackQuestions[idx]\n",
    "        question['score'] = int(score) + 1\n",
    "        feed.append(question)\n",
    "    return feed\n",
    "        \n",
    "\n",
    "def getFinalFeedback(data):\n",
    "    for i,v in data['nodes'].items():\n",
    "        if \"Final Feedback\" == v['label']:\n",
    "            return {\n",
    "                 'scores': parseFeedback(v['state']['finalFeedbackArr']), 'comment': v['state'][\"finalFeedbackComment\"]\n",
    "            }\n",
    "    return []\n",
    "\n",
    "def getAccuracy2(user, code):\n",
    "    userArr = [1 if i in user else 0 for i in range(len(code))]\n",
    "    userCorrect = 0\n",
    "    userPenalize = 0\n",
    "    maxPossiblePoints = 0\n",
    "    minPossiblePoints = 0\n",
    "    \n",
    "    for u,c in zip(userArr, code):\n",
    "        if c >= 4:\n",
    "            maxPossiblePoints += 1\n",
    "        if c == 0:\n",
    "            minPossiblePoints -= 1\n",
    "        if c >= 4 and u == 1:\n",
    "            userCorrect += 1\n",
    "        if c == 0 and u == 1:\n",
    "            userPenalize -= 1\n",
    "    \n",
    "    accuracy = interp(userCorrect + userPenalize, [minPossiblePoints, maxPossiblePoints], [0,1])\n",
    "    \n",
    "    return round(accuracy, 2)\n",
    "\n",
    "def getAccuracy(user, code, id):\n",
    "  userArr = [1 if i in user else 0 for i in range(len(code))]\n",
    "\n",
    "  ua = []\n",
    "  ca = []\n",
    "\n",
    "  for u,c in zip(userArr, code):\n",
    "    if c >= 4 or c <= 1:\n",
    "      ua.append(u)\n",
    "      ca.append(c)\n",
    "  ca = [1 if i > 1 else 0 for i in ca]\n",
    "\n",
    "  return 1 - jaccard(ua,ca)\n",
    "\n",
    "def getStudyResultsFor(data, idx = 0):\n",
    "    df = parseCode(data)\n",
    "    finalFeedback = {}\n",
    "\n",
    "    feedbackScores = getFinalFeedback(data)\n",
    "\n",
    "    partId = \"\"\n",
    "    for i in data['nodes'].keys():\n",
    "        partId = data['nodes'][i]['state']['participantId']\n",
    "        break\n",
    "    if len(partId) == 0: return\n",
    "\n",
    "    finalData = {}\n",
    "    finalData['finalFeedback'] = copy.deepcopy(feedbackScores)\n",
    "\n",
    "    demographics = {}\n",
    "    info = pmd[pmd['participant_id'] == partId]\n",
    "    # info = prolificMetaData[prolificMetaData['participant_id'] == partId]\n",
    "    if info.shape[0] > 0:\n",
    "        demographics['country_birth'] = info[\"Country of Birth\"].values[0]\n",
    "        demographics['country_residence'] = info[\"Current Country of Residence\"].values[0]\n",
    "        demographics['employment'] = info[\"Employment Status\"].values[0]\n",
    "        demographics['nationality'] = info[\"Nationality\"].values[0]\n",
    "        demographics['sex'] = info[\"Sex\"].values[0]\n",
    "        demographics['student_status'] = info[\"Student Status\"].values[0]\n",
    "        finalData['demographics'] = demographics\n",
    "    \n",
    "    overAllAcc = 0\n",
    "\n",
    "    \n",
    "    finalData['tasks'] = {}\n",
    "\n",
    "    for i,row in df.iterrows():\n",
    "        id = row['id']\n",
    "        taskDets = {**row.to_dict()}\n",
    "        selections = row['selections']\n",
    "        # del taskDets['selections']\n",
    "        rel_code = []\n",
    "        try:\n",
    "          rel_code = codeDict[int(id)]\n",
    "        except:\n",
    "          rel_code = [0] * len(selections)\n",
    "        accuracy = getAccuracy(selections, rel_code, id)\n",
    "        taskDets['accuracy'] = accuracy\n",
    "        overAllAcc += accuracy\n",
    "        taskDets[\"group\"] = f\"{taskDets['difficulty']}_{taskDets['user-driven']}_{taskDets['type']}\"\n",
    "        if taskDets['type'] == 'outlier':\n",
    "          taskDets['group'] = f\"{taskDets['group']}_{outlierBaseTypeDict[taskDets['dataset']]}\"\n",
    "        finalData['tasks'][id] = taskDets\n",
    "\n",
    "    finalData['participantId'] = partId\n",
    "    finalData['avgAcc'] = overAllAcc / df.shape[0]\n",
    "    return {'data': finalData}\n",
    "\n",
    "def getStudyResults(arr):\n",
    "    data = []\n",
    "    for i,d in enumerate(arr):\n",
    "        data.append(getStudyResultsFor(d,i))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShape(arr):\n",
    "  prov_runs = []\n",
    "  count = 1\n",
    "  for part in arr:\n",
    "    count += 1\n",
    "    data = getFromMainDB(part)\n",
    "    studyId = list(data.keys())[0]\n",
    "    sessionId = list(data[studyId].keys())[-1]\n",
    "    d = data[studyId][sessionId]\n",
    "    prov_runs.append(d)\n",
    "  return prov_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "partInfo = pd.read_csv(\"Data/partInfo.csv\")\n",
    "pmd = partInfo\n",
    "partIds = partInfo.loc[:, ['participant_id']].values[:,0]\n",
    "\n",
    "prov_runs = getShape(partIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studyProvenance = getStudyProvenanceForMultiple(prov_runs)\n",
    "len(studyProvenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_results = getStudyResults(prov_runs)\n",
    "len(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
